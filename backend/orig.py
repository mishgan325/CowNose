import streamlit as st
from PIL import Image, ImageOps
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as T
import torchvision.models as models
from ultralytics import YOLO
from sklearn.metrics.pairwise import cosine_similarity

try:
    import faiss
except ImportError:
    faiss = None


# –ö–ª–∞—Å—Å—ã –¥–ª—è SimCLR (–Ω—É–∂–Ω—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏)
class ProjectionHead(nn.Module):
    def __init__(self, in_dim=2048, hidden_dim=512, out_dim=128):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, out_dim)
        )

    def forward(self, x):
        return nn.functional.normalize(self.net(x), dim=1)


class SimCLR(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        self.backbone.fc = nn.Identity()
        self.projector = ProjectionHead(2048)

    def forward(self, x):
        h = self.backbone(x)
        z = self.projector(h)
        return z


# –ö—ç—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π
@st.cache_resource
def load_yolo_model():
    return YOLO('best.pt')


@st.cache_resource
def load_simclr_model():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = SimCLR()
    checkpoint = torch.load('simclr_cow_model.pth', map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    return model.to(device)


@st.cache_data
def load_embeddings():
    return np.load("cow_embeddings.npy", allow_pickle=True).item()


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def get_embedding(model, image):
    device = next(model.parameters()).device
    transform = T.Compose([
        T.Resize(256),
        T.CenterCrop(224),
        T.ToTensor(),
        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    img_tensor = transform(image).unsqueeze(0).to(device)
    with torch.no_grad():
        emb = model.backbone(img_tensor).squeeze().cpu().numpy()
        return emb / np.linalg.norm(emb)


# –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤
def find_similar_cows(query_embedding, embeddings_db, top_k=3):
    query_vector = query_embedding.reshape(1, -1)
    names = list(embeddings_db.keys())
    all_vectors = np.stack([embeddings_db[name] for name in names])

    if faiss is not None:
        index = faiss.IndexFlatIP(all_vectors.shape[1])
        index.add(all_vectors.astype('float32'))
        D, I = index.search(query_vector.astype('float32'), top_k)

        results = []
        for i, idx in enumerate(I[0]):
            results.append({
                'name': names[idx],
                'similarity': float(D[0][i])
            })
        return results
    else:
        sims = cosine_similarity(query_vector, all_vectors)[0]
        top_idxs = sims.argsort()[::-1][:top_k]

        results = []
        for idx in top_idxs:
            results.append({
                'name': names[idx],
                'similarity': float(sims[idx])
            })
        return results


def convert_coordinates(xywh, img_width, img_height):
    x_center, y_center, w, h = xywh
    left = (x_center - w / 2) * img_width
    right = (x_center + w / 2) * img_width
    top = (y_center - h / 2) * img_height
    bottom = (y_center + h / 2) * img_height
    return int(left), int(top), int(right), int(bottom)


# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
yolo_model = load_yolo_model()
simclr_model = load_simclr_model()
embeddings_db = load_embeddings()

st.title("üêÆ –î–µ—Ç–µ–∫—Ç–æ—Ä –∏ –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ –∫–æ—Ä–æ–≤—ã –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –Ω–æ—Å–∞ –∏ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤ –≤ –±–∞–∑–µ")

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...",
    type=["jpg", "jpeg", "png"],
    help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ 200MB"
)

if uploaded_file is not None:
    st.subheader("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    original_image = Image.open(uploaded_file).convert("RGB")
    original_image = ImageOps.exif_transpose(original_image)
    st.image(original_image, use_column_width=True)

    if st.button("üîç –ù–∞–π—Ç–∏ –Ω–æ—Å –∏ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤", type="primary"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ numpy array
            img_array = np.array(original_image)

            # –î–µ—Ç–µ–∫—Ü–∏—è –Ω–æ—Å–∞
            results = yolo_model.predict(img_array)

            if len(results[0].boxes) == 0:
                st.error("–ù–æ—Å –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                st.stop()

            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –Ω–æ—Å
            xywhn = results[0].boxes.xywhn[0].cpu().numpy()
            img_width, img_height = original_image.size

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            left, top, right, bottom = convert_coordinates(
                xywhn,
                img_width,
                img_height
            )

            # –û–±—Ä–µ–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–æ—Å–∞
            cropped_nose = original_image.crop((left, top, right, bottom))

            # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–æ—Å–∞
            nose_embedding = get_embedding(simclr_model, cropped_nose)

            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤
            similar_cows = find_similar_cows(nose_embedding, embeddings_db, top_k=3)

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –Ω–æ—Å**")
                st.image(cropped_nose, use_column_width=True)

            with col2:
                st.markdown("**–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–æ—Å–∞**")
                st.json({
                    "left": left,
                    "top": top,
                    "right": right,
                    "bottom": bottom,
                    "width": right - left,
                    "height": bottom - top
                })

            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤
            st.subheader("üéØ –¢–æ–ø-3 –ø–æ—Ö–æ–∂–∏—Ö –∫–æ—Ä–æ–≤—ã –≤ –±–∞–∑–µ")

            cols = st.columns(3)
            for i, cow in enumerate(similar_cows):
                with cols[i]:
                    st.markdown(f"**#{i + 1}: {cow['name']}**")
                    st.markdown(f"**–°—Ö–æ–∂–µ—Å—Ç—å: {cow['similarity']:.4f}**")

                    st.image(f"cow_f_crop/{cow['name']}")

                    if cow['similarity'] > 0.9:
                        st.success("–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ!")
                    elif cow['similarity'] > 0.8:
                        st.info("–•–æ—Ä–æ—à–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ")
                    else:
                        st.warning("–£–º–µ—Ä–µ–Ω–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ")

        st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

        with st.expander("‚ÑπÔ∏è –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
            st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ—Ä–æ–≤ –≤ –±–∞–∑–µ:** {len(embeddings_db)}")
            st.write(f"**–†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞:** {nose_embedding.shape[0]} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
            st.write("**–ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞:** " + ("FAISS" if faiss else "Cosine Similarity"))
